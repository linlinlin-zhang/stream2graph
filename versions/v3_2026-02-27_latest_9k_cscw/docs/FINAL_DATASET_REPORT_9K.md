# Stream2Graph 9,000 高质量数据集最终生成报告

**报告时间**: 2026-02-26
**目标版本**: 最终混合版 (9,000 条)

---

## 1. 数据规模与构成

经过多个阶段的“数据采集、合规清洗、语法抢救、Kroki 引擎强制渲染测试以及结构感知型数据增强”，Stream2Graph 数据集目前已精准达到 **9,000 条** 的大关。所有数据均 100% 保证可被渲染，无语法残缺。

| 数据类别 | 数据来源/操作手段 | 数量 | 占比 |
| :--- | :--- | :--- | :--- |
| **纯真实数据 (Real)** | GitHub 存量提纯 (`v3` 目录) | 2,649 | 29.4% |
| **纯真实数据 (Real)** | GitHub API 深度检索新增 (`v4` 目录) | 351 | 3.9% |
| **真实数据小计** | **真实开发者编写的 Mermaid 源码** | **3,000** | **33.3%** |
| **增强数据 (Augmented)** | 结构感知型算法衍生 (`v5` 目录) | 6,000 | 66.7% |
| **总计黄金数据** | **高质量、可编译图表代码** | **9,000** | **100%** |

---

## 2. 数据质量保障协议

为确保数据集在学术和工程上的有效性，我们在构建过程中严格执行了以下协议：

1. **闭环渲染验证 (Kroki API)**：每一条入库的数据（无论是真实抓取还是增强生成）都必须能在 Kroki 引擎中成功转换为 SVG/PNG 图像，拦截了所有带有语法错误的代码。
2. **结构保真策略 (Structure-Aware)**：在生成 6,000 条增强数据时，我们完全保留了真实图表复杂的拓扑连接关系，仅针对节点 Label 注入特定领域的语义（如 FinTech、HealthTech），从而解决了复杂图表“长尾分布”的问题。
3. **极限抢救补全**：面对 API 限流墙，我们通过自研的自动括号修复及非法字符清洗算法，成功将数百个被误杀的存量真实图表救回。

---

## 3. 后续工作流

本报告生成后，将立即触发流水线的最后两个阶段：

*   **大合拢 (Merge)**：将分散在 `v3`、`v4`、`v5` 的三个数据池统一汇聚到 `final_v2_9k`。
*   **对话逆向工程 (Dialogue Reverse Engineering)**：针对这 9,000 个图表结构，算法将根据“言语行为理论 (Speech Act Theory)”模拟两人对话，逐步将图表拆解为多轮“自然语言需求 -> 代码变更”的数据对。

---
*由 Gemini 驱动的数据集自动化管线生成。*