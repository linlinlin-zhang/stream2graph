# Stream2Graph 数据集深度审计报告

**报告时间**: 2026-02-25
**审计范围**: `/home/lin-server/pictures/` 及其子目录

## 1. 总体概况

经过对整个项目目录的深度扫描和对断点文件的分析，当前数据集状态与项目预定目标（8,000条高质量样本）存在显著差距。

| 指标 | 目标值 | 实际检测值 | 状态 |
|------|--------|------------|------|
| 总样本数 | 8,000 | 6,396 (ID唯一) | ❌ 未达标 |
| 唯一图表数 | 8,000 | 4,374 (代码唯一) | ❌ 存在 1,331 条重复 |
| 可编译率 | >90% | ~45% (Kroki抽检) | ❌ 质量存疑 |
| 许可证覆盖率 | 高 (100%合规) | 43% (检测到许可证) | ⚠️ 57% 为 "none" |

## 2. 来源分布审计

数据来源多样性不足，且部分核心来源数据丢失。

| 来源 | 数量 | 占比 | 备注 |
|------|------|------|------|
| GitHub | 3,613 | 56.5% | 主要来源，质量相对最高 |
| Other | 1,200 | 18.8% | 主要是 Gist 或其他零散来源 |
| GitLab | 806 | 12.6% | 补充来源 |
| Synthetic | 750 | 11.7% | 变体生成 |
| HuggingFace | 27 | 0.4% | **严重丢失**: 原定 2,400 条因质量问题被删除 |

## 3. 许可证信息审计

许可证合规性是项目的一个重大风险点。

- **有效许可证**: 2,766 条 (MIT, Apache, GPL 等)
- **无许可证 (none)**: 3,630 条
- **分布**: GitHub 来源的样本大部分标记为 `none` 或 `other_source`，这会影响数据集的公开发布。

## 4. 可编译性与数据质量审计

之前记录的 62.2% 成功率是在 Windows 环境下运行的结果，且由于环境错误（WinError 2）导致大量误报。

- **当前状态**: `final_100percent_real` 目录下的 5,603 个 JSON 文件全部标记为 `compilation_status: "failed"`。
- **重新验证**: 在 Linux 环境下使用 Kroki 引擎进行随机抽检，实际成功率仅为 **45.0%**。
- **主要问题**: 
    - 包含非标准 Mermaid 语法（可能是旧版本或特定插件语法）。
    - 提取的代码片段不完整（缺少 `graph TD` 等声明）。
    - 混入了非图表代码的普通文本或代码片段。

## 5. 项目完整性风险

- **`05_final` 目录异常**: 该目录下虽然有 8,003 个文件夹，但 **全部为空**。
- **`dataset_index.json` 不一致**: 该索引文件仅包含 3,218 条样本，与 8,000 条的目标不符。
- **丢失数据**: 逆向工程生成的对话数据（Dialogue）在文件系统中几乎不可见，除了 `dataset_index.json` 中嵌入的部分内容。

## 6. 建议与后续行动

1. **重新清洗**: 排除那 45% 无法编译的样本，以及 1,331 条重复样本。
2. **重新收集**: 需要重新从 GitHub 或其他高质量来源收集约 4,000-5,000 条真实数据，以填补 HuggingFace 数据的空缺。
3. **修复许可证**: 针对 `none` 类型的 GitHub 样本，可以尝试重新爬取其所属仓库的 LICENSE 文件。
4. **重新生成对话**: 鉴于 `05_final` 数据丢失，需要重新运行 `dialogue_reverse_engineering.py` 或类似脚本。

---
*审计人: Gemini CLI*
