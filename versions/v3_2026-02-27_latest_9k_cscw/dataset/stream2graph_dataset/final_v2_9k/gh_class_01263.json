{
  "id": "gh_class_01263",
  "source": "github",
  "source_url": "https://github.com/jonykalavera/kafkaescli/blob/498786a2e31c7573fada32eb4592e14cb0e1741e/docs/diagrams/classes_kafkaescli.infra.mmd",
  "github_repo": "jonykalavera/kafkaescli",
  "github_file_path": "docs/diagrams/classes_kafkaescli.infra.mmd",
  "diagram_type": "class",
  "code": "classDiagram\n  class AIOKafkaConsumer {\n    assign(partitions)\n    assignment()\n    beginning_offsets(partitions)\n    commit(offsets)\n    committed(partition)\n    end_offsets(partitions)\n    getmany()\n    getone()\n    highwater(partition)\n    last_poll_timestamp(partition)\n    last_stable_offset(partition)\n    offsets_for_times(timestamps)\n    partitions_for_topic(topic)\n    pause()\n    paused()\n    position(partition)\n    resume()\n    seek(partition, offset)\n    seek_to_beginning()\n    seek_to_committed()\n    seek_to_end()\n    start()\n    stop()\n    subscribe(topics, pattern, listener)\n    subscription()\n    topics()\n    unsubscribe()\n  }\n  class AIOKafkaProducer {\n    client : AIOKafkaClient\n    abort_transaction()\n    begin_transaction()\n    commit_transaction()\n    create_batch()\n    flush()\n    partitions_for(topic)\n    send(topic, value, key, partition, timestamp_ms, headers)\n    send_and_wait(topic, value, key, partition, timestamp_ms, headers)\n    send_batch(batch, topic)\n    send_offsets_to_transaction(offsets, group_id)\n    start()\n    stop()\n    transaction()\n  }\n  class ClientSession {\n    ATTRS : frozenset\n    auth\n    auto_decompress\n    closed\n    connector\n    connector_owner\n    cookie_jar\n    headers\n    json_serialize\n    loop\n    raise_for_status\n    requote_redirect_url\n    skip_auto_headers\n    timeout\n    trace_configs\n    trust_env\n    version\n    close() -> None\n    delete(url: StrOrURL) -> '_RequestContextManager'\n    detach() -> None\n    get(url: StrOrURL) -> '_RequestContextManager'\n    head(url: StrOrURL) -> '_RequestContextManager'\n    options(url: StrOrURL) -> '_RequestContextManager'\n    patch(url: StrOrURL) -> '_RequestContextManager'\n    post(url: StrOrURL) -> '_RequestContextManager'\n    put(url: StrOrURL) -> '_RequestContextManager'\n    request(method: str, url: StrOrURL) -> '_RequestContextManager'\n    ws_connect(url: StrOrURL) -> '_WSRequestContextManager'\n  }\n  class ConfigService {\n    config_file_service : ConfigFileService\n    overrides : Optional[dict]\n    profile_name : Optional[str]\n    execute() -> Settings\n  }\n  class Consumer {\n    config_service\n    execute(topics: List[str], group_id: Optional[str], enable_auto_commit: bool, auto_offset_reset: str, auto_commit_interval_ms: int) -> AsyncIterator[ConsumerPayload]\n  }\n  class Container {\n    config_file_path\n    config_file_service\n    config_service\n    consume_service\n    consumer\n    hook_after_consume\n    hook_before_produce\n    overrides\n    produce_service\n    producer\n    profile_name\n    webhook_handler\n  }\n  class Producer {\n    config_service\n    execute(topic: str, value: bytes, key: Optional[bytes], partition) -> ProducerPayload\n  }\n  class Settings {\n    bootstrap_servers : str\n    middleware : List[Middleware]\n  }\n  class WebhookHandler {\n    execute()\n    send(webhook: Optional[str], payload: ConsumerPayload) -> None\n  }\n  ClientSession --* WebhookHandler : _session\n  ClientSession --* WebhookHandler : _session\n  AIOKafkaConsumer --* Consumer : _consumer\n  AIOKafkaProducer --* Producer : _producer\n  Settings --* Producer : _config\n  ConfigService --* Consumer : config_service\n  ConfigService --* Producer : config_service\n",
  "content_size": 3190,
  "collected_at": "2026-02-06T01:55:21.751352",
  "compilation_status": "failed",
  "compilation_error": "[WinError 2] 系统找不到指定的文件。",
  "license": "mit",
  "license_name": "MIT License",
  "license_url": "https://api.github.com/licenses/mit",
  "repo_stars": 2,
  "repo_forks": 1
}