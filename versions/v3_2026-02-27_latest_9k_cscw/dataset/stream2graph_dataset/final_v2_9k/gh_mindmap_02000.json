{
  "id": "gh_mindmap_02000",
  "source": "github",
  "source_url": "https://github.com/Rethishkumar/DDIA/blob/30c65cae1d4613fef3916d49d399425fe74c3dfe/mindmap/replication_leaderbased.mmd",
  "github_repo": "Rethishkumar/DDIA",
  "github_file_path": "mindmap/replication_leaderbased.mmd",
  "diagram_type": "mindmap",
  "code": "mindmap\n  root((Replication))\n    id1[\"`**Single Leader / Leader Based**. Clients send writes to leader. Leader writes to local storage and sends change to followers.`\"]\n        Sync/Async Replication\n            id1[\"`**Sync** All followers written in sync. Not usualy used as can't make all followers sync`\"]\n            id1[\"`**Semi-Sync** Some followers written in sync and others async.`\"]\n            id1[\"`**Async** All followers written in Async. Leader can still continue processing writes. Used more widely used than others`\"]\n        Handling Node Outages\n            id1[\"`**Follower failure - Catchup Recovery** Each follower keeps log of data chnages recvd from leader. When joining back requestes changes since last disconected.`\"]\n            id1[\"`**Leader failure - Failover** On leader outage. Clients need to be reconfigured to send to new leader.`\"]\n                id1[\"`**Failover process**\n                *Determine leader has failed*: Via say heartbeats \n                *Chosing New Leader*: Via election process or via a controlling node. Usually leader is node that las latest update. \n                *Reconfiguring system for new leader*: Clients need to send to new leader. New leader when coming back should join as follwer and not leader`\"]\n                id1[\"`**Failover Gotchas** \n                *Conflicts*: if leader was written to during outage there could be conflicting writes\n                *Keys*: If conflicting data is discarded. sequential keys generated in new leader and old leader may get overwritten causing user to see others data etc\n                *Split Brain:* Safety mechanisms required for ensuring only one leader exists\n                *Leader Timeout:* Long timeout causes longer recocovery. Shorter Timeouts cause oscillating and unnecessary failures.`\"]\n        How does Leader based replication work?\n            id1[\"`**Statement based relication** \n            Each write request statement is sent to followers.\n            *Cons:* some statement may have calaucted values or auto incrementing sequences or side effects such as triggers.\n            Not generally preferred`\"]\n            id1[\"`**Write Ahead Logs (WAL) shipping** \n            The LSM tree log statement (physical data representation) is sent to followers. Follower processes the log and build a replica.\n            *Cons:* The logs are in machine native format. So version upgrades etc are difficult. Leaders and followers should be on same version.`\"]\n            id1[\"`**Logical (row-based) replication** \n            Log statement is logical info eg; For an insert all values of columns, For deletion the primary key etc.\n            Easier for external tools to parse and use ; Used in Change Data Capture.`\"]\n            id1[\"`**Trigger based replication** \n            Triggeres done to application code and application code responsible for replicaticating data chnage. Uses Triggeres/Stored Procedures.`\"]\n        Problems with replication\n            id1[\"`**Read own Writes** \n                Application writes to leader and reads from a follower which doesn't have the update. \n                *Solution:* Read own updates from leader itself. eg. user profile update should always be from leader. other profiles may be from followers.\n                OR on an update read from leader for some duration and after that read from followers.\n                OR add a counter for each update and if read from follower has a lower counter read from somewhere else.\n                *Cons*: Cross device reads can't track upates so would get stale information`\"]\n            id1[\"`**Monotonic Reads**\n                App reads from replica which has Update U2 but next read on another replica with previous update. So app may see updates going backward\n                Monotonic reads is a gurantee < Strong consistency but > eventual.\n                *Solution:* App always reads from same replica or set of replica. The replica(set) is determined via User Id hash.`\"]\n            id1[\"`**Consistent Prefix Reads**\n                Sequence of writes happen in an order and reads for them also happen in order.\n                Else, Updates to related information can go out of sync.`\"]\n        Solution for replication lag: Transactions\n        \n\n\n",
  "content_size": 4291,
  "collected_at": "2026-02-06T02:06:15.758445",
  "compilation_status": "success",
  "license": "mit",
  "license_name": "MIT License",
  "license_url": "https://api.github.com/licenses/mit",
  "repo_stars": 0,
  "repo_forks": 0,
  "repo_owner": "Rethishkumar",
  "repo_name": "DDIA",
  "repo_description": "Learning from Designing Data Intensive Applications",
  "repo_language": "Mermaid",
  "repo_topics": [],
  "repo_created_at": "2024-08-11T14:31:52Z",
  "repo_updated_at": "2025-07-21T03:04:08Z"
}