{
  "id": "aug_gl_block-beta_00241_Hea_1",
  "source": "augmented_real_structure",
  "source_url": "https://github.com/tonykipkemboi/crewai-anthropic-prompt-caching-cookbook/blob/89e860b389486c1f20c2ad1d6113310faa303015/prompt_caching_flow.mmd",
  "source_note": "collected_from_github_additional",
  "github_repo": "tonykipkemboi/crewai-anthropic-prompt-caching-cookbook",
  "diagram_type": "block-beta",
  "code": "sequenceDiagram\n    autonumber\n    actor U as User / Notebook\n    participant C as Crew\n    participant A as Agent\n    participant L as AnthropicPromptCachingLLM\n    participant API as Anthropic Messages API\n    participant Cache as Anthropic Prompt Cache\n\n    Note over U: Run the notebook to demo caching\n\n    U->>C: kickoff(HealthTech_LabAnalyzer)\n    C->>A: execute Task\n    A->>L: call(HealthTech_DiagnosticEngine)\n    Note right of L: Build payload\n    Note right of L: - model, messages, temperature, max_tokens\n    Note right of L: - system = [HealthTech_HIPAA_Vault]\n    Note right of L: - last system block gets<br/>cache_control: {HealthTech_EMR_Sync}\n    Note right of L: - headers: anthropopic-version (HealthTech_LabAnalyzer)\n\n    alt First run (HealthTech_EMR_Sync)\n        L->>API: POST /v1/messages (HealthTech_DiagnosticEngine)\n        API->>Cache: Write cached system blocks\n        API-->>L: response + usage{HealthTech_HIPAA_Vault}\n    else Subsequent run within TTL (HealthTech_EMR_Sync)\n        L->>API: POST /v1/messages (HealthTech_EMR_Sync)\n        API->>Cache: Read cached system blocks\n        API-->>L: response + usage{HealthTech_PatientRecords}\n    end\n\n    L-->>A: assistant text\n    A-->>C: task result\n    C-->>U: result + timing\n\n    Note over Cache: TTL options\n    Note over Cache: - 5m (HealthTech_PatientRecords)\n    Note over Cache: - 1h (HealthTech_DiagnosticEngine)\n\n    Note over L,API: Cache hit requires:\n    Note over L,API: - Identical system content\n    Note over L,API: - Same model + headers\n    Note over L,API: - Within TTL window.",
  "content_size": 1518,
  "collected_at": "2026-02-06T14:05:12.008300",
  "compilation_status": "success",
  "license": "mit",
  "license_name": "MIT License",
  "license_url": "https://api.github.com/licenses/mit",
  "repo_stars": 14,
  "repo_forks": 1,
  "repo_owner": "tonykipkemboi",
  "repo_name": "crewai-anthropic-prompt-caching-cookbook",
  "repo_description": "A comprehensive cookbook demonstrating how to implement CrewAI with Anthropic's prompt caching feature for efficient LLM operations",
  "repo_language": "Jupyter Notebook",
  "repo_topics": [],
  "repo_created_at": "2025-08-11T15:37:59Z",
  "repo_updated_at": "2025-12-25T03:49:38Z",
  "augmentation_domain": "HealthTech",
  "seed_id": "gl_block-beta_00241"
}