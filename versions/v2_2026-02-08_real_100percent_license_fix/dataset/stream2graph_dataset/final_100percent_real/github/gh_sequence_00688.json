{
  "id": "gh_sequence_00688",
  "source": "github",
  "source_url": "https://github.com/ormastes/aidev/blob/a7598a83c9be9bdc9a841015cb0d9a53dd3d33b6/layer/themes/infra_external-log-lib/user-stories/003-structured-log-parsing/docs/diagrams/mermaid_system_sequence.mmd",
  "github_repo": "ormastes/aidev",
  "github_file_path": "layer/themes/infra_external-log-lib/user-stories/003-structured-log-parsing/docs/diagrams/mermaid_system_sequence.mmd",
  "diagram_type": "sequence",
  "code": "```mermaid\nsequenceDiagram\n    participant Dev as Developer\n    participant Platform as AIDevPlatform\n    participant Parser as StructuredLogParser\n    participant Process as External Process\n    participant FileSystem as File System\n\n    Note over Dev, FileSystem: Scenario 1: Parse JSON logs from Node.js application\n    \n    Dev->>Platform: startLogCapture({<br/>command: 'node',<br/>args: ['app.js'],<br/>captureOutput: true,<br/>logFormat: 'json'<br/>})\n    Platform->>Process: spawn('node', ['app.js'])\n    Platform->>Parser: createStructuredParser('json')\n    Platform-->>Dev: LogCaptureSession\n    \n    loop JSON Log Processing\n        Process->>Parser: {\"timestamp\":\"2025-01-15T10:00:00.000Z\",<br/>\"level\":\"info\",<br/>\"message\":\"Server started\",<br/>\"meta\":{\"port\":3000}}\n        Parser->>Parser: validateJSONSchema()\n        Parser->>Parser: extractFields()\n        Parser-->>Platform: LogEntry{timestamp, level, message, metadata}\n    end\n    \n    Dev->>Platform: session.getLogs()\n    Platform-->>Dev: LogEntry[] with parsed metadata\n    \n    Dev->>Platform: session.getMetadata('port')\n    Platform-->>Dev: 3000\n\n    Note over Dev, FileSystem: Scenario 2: Parse custom structured format (key=value)\n    \n    Dev->>Platform: startLogCapture({<br/>command: 'custom-app',<br/>args: [],<br/>captureOutput: true,<br/>logFormat: 'key-value'<br/>})\n    Platform->>Process: spawn('custom-app', [])\n    Platform->>Parser: createStructuredParser('key-value')\n    Platform-->>Dev: LogCaptureSession\n    \n    Process->>Parser: timestamp=2025-01-15T10:00:00Z level=ERROR message=\"Database connection failed\" error_code=1234 retry_count=3\n    Parser->>Parser: parseKeyValuePairs()\n    Parser->>Parser: normalizeTypes()\n    Parser-->>Platform: LogEntry with structured data\n    \n    Dev->>Platform: session.filterByMetadata('error_code', 1234)\n    Platform-->>Dev: Filtered LogEntry[]\n\n    Note over Dev, FileSystem: Scenario 3: Parse XML/YAML logs\n    \n    Dev->>Platform: startLogCapture({<br/>command: 'java',<br/>args: ['-jar', 'app.jar'],<br/>captureOutput: true,<br/>logFormat: 'xml'<br/>})\n    Platform->>Process: spawn('java', ['-jar', 'app.jar'])\n    Platform->>Parser: createStructuredParser('xml')\n    Platform-->>Dev: LogCaptureSession\n    \n    Process->>Parser: <log><timestamp>2025-01-15T10:00:00Z</timestamp><br/><level>WARN</level><br/><message>Memory usage high</message><br/><memory>1.2GB</memory></log>\n    Parser->>Parser: parseXML()\n    Parser->>Parser: mapToLogEntry()\n    Parser-->>Platform: LogEntry with structured fields\n    \n    Dev->>Platform: session.exportAsJSON()\n    Platform-->>Dev: JSON representation of all logs\n\n    Note over Dev, FileSystem: Scenario 4: Mixed format handling\n    \n    Dev->>Platform: startLogCapture({<br/>command: 'mixed-app',<br/>args: [],<br/>captureOutput: true,<br/>logFormat: 'auto'<br/>})\n    Platform->>Parser: createStructuredParser('auto')\n    \n    Process->>Parser: {\"level\":\"info\",\"msg\":\"JSON log\"}\n    Parser->>Parser: detectFormat() → JSON\n    Parser-->>Platform: Parsed JSON LogEntry\n    \n    Process->>Parser: 2025-01-15 ERROR: Plain text log\n    Parser->>Parser: detectFormat() → Plain text\n    Parser-->>Platform: Basic LogEntry\n    \n    Process->>Parser: level=debug msg=\"Key-value log\" \n    Parser->>Parser: detectFormat() → Key-Value\n    Parser-->>Platform: Parsed KV LogEntry\n\n    Note over Dev, FileSystem: Scenario 5: Schema validation and error handling\n    \n    Dev->>Platform: defineLogSchema({<br/>required: ['timestamp', 'level'],<br/>properties: {level: {enum: ['debug','info','warn','error']}}<br/>})\n    \n    Process->>Parser: {\"message\":\"Missing required fields\"}\n    Parser->>Parser: validateSchema() → Invalid\n    Parser-->>Platform: LogEntry{level: 'error', message: 'Invalid log format: Missing required field: timestamp'}\n    \n    Dev->>Platform: session.getInvalidLogs()\n    Platform-->>Dev: LogEntry[] of validation failures\n\n    Note over Dev, FileSystem: Scenario 6: Save structured logs\n    \n    Dev->>Platform: session.saveStructuredLogs('logs.json', {<br/>format: 'json',<br/>includeMetadata: true<br/>})\n    Platform->>FileSystem: Write structured JSON file\n    FileSystem-->>Platform: Success\n    Platform-->>Dev: File saved\n```\n\n## Structured Log Parsing System Scenarios\n\n### Key Features Required\n\n1. **Multiple Format Support**\n   - JSON parsing with nested objects\n   - Key-value pair parsing (logfmt style)\n   - XML log parsing\n   - YAML log parsing\n   - Auto-detection of format\n\n2. **Schema Validation**\n   - Define expected log schemas\n   - Validate incoming logs against schema\n   - Handle validation errors gracefully\n\n3. **Metadata Extraction**\n   - Extract structured fields beyond basic log entry\n   - Support nested metadata\n   - Type normalization (strings to numbers, dates, etc.)\n\n4. **Query and Filter**\n   - Filter logs by metadata values\n   - Query nested fields\n   - Export in different formats\n\n5. **Error Handling**\n   - Graceful fallback for unparseable logs\n   - Track validation failures\n   - Mixed format support in single stream\n\n### Test Requirements\n\nBased on these scenarios, we need:\n\n1. **Environment Tests**\n   - JSON output from Node.js process\n   - Key-value format from custom applications\n   - XML output from Java applications\n   - Mixed format streams\n\n2. **External Tests**\n   - StructuredLogParser with different formats\n   - Schema validation\n   - Format auto-detection\n\n3. **Integration Tests**\n   - Parser integration with log capturer\n   - Metadata extraction and querying\n   - Mixed format handling\n\n4. **System Tests**\n   - End-to-end structured log parsing\n   - Schema validation in real scenarios\n   - Export functionality\n\n5. **Unit Tests**\n   - Individual parser implementations\n   - Schema validator\n   - Metadata extractor\n   - Format detector",
  "content_size": 5798,
  "collected_at": "2026-02-06T01:35:42.064626",
  "compilation_status": "failed",
  "compilation_error": "[WinError 2] 系统找不到指定的文件。",
  "license": "none",
  "license_name": "No License",
  "license_url": "",
  "repo_stars": 0,
  "repo_forks": 0
}