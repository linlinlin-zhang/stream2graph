{
  "id": "gh_class_01017",
  "source": "github",
  "source_url": "https://github.com/lusing/misc/blob/718b401b9e22350c77f9afa3d8140ea728a9f514/docs/ai/mermaid/dqn.mmd",
  "github_repo": "lusing/misc",
  "github_file_path": "docs/ai/mermaid/dqn.mmd",
  "diagram_type": "class",
  "code": "\nclassDiagram\n    class BaseAlgorithm {\n        +policy_aliases: ClassVar[Dict[str, Type[BasePolicy]]]\n        +policy: BasePolicy\n        +observation_space: spaces.Space\n        +action_space: spaces.Space\n        +n_envs: int\n        +lr_schedule: Schedule\n        +set_logger(logger: Logger) None\n        +logger: Logger\n        +get_env() Optional[VecEnv]\n        +get_vec_normalize_env() Optional[VecNormalize]\n        +set_env(env: GymEnv, force_reset: bool = True) None\n        +learn(self: SelfBaseAlgorithm, ...) Tuple[np.ndarray, Optional[Tuple[np.ndarray, ...]]]\n        +set_random_seed(seed: Optional[int] = None) None\n        +set_parameters(load_path_or_dict: Union[str, TensorDict], ...) None\n        +load(cls: Type[SelfBaseAlgorithm], ...) SelfBaseAlgorithm\n        +get_parameters() Dict[str, Dict]\n        +save(path: Union[str, pathlib.Path, io.BufferedIOBase], ...) None\n    }\n\n    class OffPolicyAlgorithm {\n        +policy: Union[str, Type[BasePolicy]]\n        +env: Union[GymEnv, str]\n        +learning_rate: Union[float, Schedule]\n        +buffer_size: int\n        +learning_starts: int\n        +batch_size: int\n        +tau: float\n        +gamma: float\n        +train_freq: Union[int, Tuple[int, str]]\n        +gradient_steps: int\n        +action_noise: Optional[ActionNoise]\n        +replay_buffer_class: Optional[Type[ReplayBuffer]]\n        +replay_buffer_kwargs: Optional[Dict[str, Any]]\n        +policy_kwargs: Optional[Dict[str, Any]]\n        +stats_window_size: int\n        +tensorboard_log: Optional[str]\n        +verbose: int\n        +device: Union[th.device, str]\n        +seed: Optional[int]\n        +sde_support: bool\n        +optimize_memory_usage: bool\n        +supported_action_spaces: Tuple[Type[spaces.Space], ...]\n        +support_multi_env: bool\n    }\n\n    class DQN {\n        +exploration_initial_eps: float\n        +exploration_final_eps: float\n        +exploration_fraction: float\n        +target_update_interval: int\n        +max_grad_norm: float\n        +exploration_rate: float\n        +exploration_schedule: Schedule\n        +q_net: QNetwork\n        +q_net_target: QNetwork\n        +policy: DQNPolicy\n        +batch_norm_stats: List[th.Tensor]\n        +batch_norm_stats_target: List[th.Tensor]\n        +train(gradient_steps: int, batch_size: int = 100) None\n        +predict(observation: Union[np.ndarray, Dict[str, np.ndarray]], ...)\n        +learn(self: SelfDQN, ...) SelfDQN\n    }\n\n    OffPolicyAlgorithm <|-- DQN\n    BaseAlgorithm <|-- OffPolicyAlgorithm\n",
  "content_size": 2512,
  "collected_at": "2026-02-06T01:51:55.950716",
  "compilation_status": "failed",
  "compilation_error": "[WinError 2] 系统找不到指定的文件。",
  "license": "mit",
  "license_name": "MIT License",
  "license_url": "https://api.github.com/licenses/mit",
  "repo_stars": 0,
  "repo_forks": 0
}