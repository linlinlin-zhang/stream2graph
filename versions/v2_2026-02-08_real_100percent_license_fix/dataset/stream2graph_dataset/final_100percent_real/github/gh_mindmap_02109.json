{
  "id": "gh_mindmap_02109",
  "source": "github",
  "source_url": "https://github.com/40Eqiuhouru/SparkSystem/blob/816f22470ac34f32f271a2edd8acb7b36ba42c17/note/Spark%E2%80%94CORE.mmd",
  "github_repo": "40Eqiuhouru/SparkSystem",
  "github_file_path": "note/Spark—CORE.mmd",
  "diagram_type": "mindmap",
  "code": "[Scia Reto](https://sciareto.org) mind map   \n> __version__=`1.1`,generatorId=`com.igormaznitsa:idea-mindmap:intellij-2024.17.0-IntelliJ IDEA`\n---\n\n# Spark\\-CORE\n> align=`center`\n\n\n## 术语\n> collapsed=`true`\n\n\n### Application\n> collapsed=`true`\n\n\n#### 启动一个 MapReduce 程序, 其实是启动了一个分布式计算程序, 最小的描述单词\n\n### Job\n> collapsed=`true`\n\n\n#### 启动了一个分布式计算程序, 其实就是间接启动了一个 Job, 在一个 Job 中只有两个阶段\n\n### Stage\n> collapsed=`true`\n\n\n#### 一个线性的过程, 在一个阶段中会有一些列并行的 Task\n\n#### MapStage\n\n#### ReduceStage\n\n### Task\n> collapsed=`true`\n\n\n#### MapTask\\(若干\\)\n> collapsed=`true`\n\n\n##### 1\\.Input\n> collapsed=`true`\n\n\n###### 2\\.map\\(\\),filter\n> collapsed=`true`\n\n\n####### 3\\.output, file, local\n\n####  ReduceTask\\(若干\\)\n> collapsed=`true`\n\n\n##### 1\\.Input\\(迭代器\\)\n> collapsed=`true`\n\n\n###### 2\\.reduce\\(\\), reduceByKey\\(嵌套迭代器\\)\n> collapsed=`true`\n\n\n####### 3\\.output\n\n### 比例 : <br/>1@App : 1@Job<br/>1@Job : 1\\-2@Stage<br/>1@Stage : N@Task\n> collapsed=`true`\n\n\n#### 如果代码中只做过滤不做统计, 可能没有 Reduce\n\n### 多个 MR 的 Job 可以组成作业链\n\n### InpoutFormat\n> collapsed=`true`\n\n\n#### TextInputFormat\n> collapsed=`true`\n\n\n##### InputFormat 的子类实现, 默认处理文本的类, 这个类有两个地方可以使用到\n\n##### 1\\.Client 中计算 splits 的数量, 间接计算 Map 数量\n\n##### 2\\.MapTask 中输入格式化类得到 LineRecordReader\\(行记录读取器\\)\n\n## 架构\n\n## 应用\n> collapsed=`true`\n\n\n### 编程模型\n> collapsed=`true`\n\n\n#### RDD\n> collapsed=`true`\n\n\n##### A Resilient Distributed Dataset\n> collapsed=`true`\n\n\n###### HadoopRDD\n> collapsed=`true`\n\n\n####### 文件数据输入\n\n###### MapPartitionsRDD\n\n##### A list of partitions SPLITS\n> collapsed=`true`\n\n\n###### HadoopRDD\n> collapsed=`true`\n\n\n####### getPartitions\n\n##### A function for computing each split\n> collapsed=`true`\n\n\n###### HadoopRDD\n> collapsed=`true`\n\n\n####### compute\\(Partition\\)\n\n##### A list of dependencies on other RDDs\n> collapsed=`true`\n\n\n###### Narrow\n\n###### Shuffle\n\n##### a Partitioner for key\\-value RDDs\n\n##### a list of preferred locations to compute each split\n\n#### 算子 \n> collapsed=`true`\n\n\n##### Create\n> collapsed=`true`\n\n\n###### sc\\.textFile\\(\\)\n\n##### Transform\n> collapsed=`true`\n\n\n###### Map, flatMap, filter\n\n###### reduceByKey/combineByKey, sortByKey\n\n##### Control\n> collapsed=`true`\n\n\n###### cache, persist, checkpoint\n\n###### repartition, colase\n\n##### Action\n> collapsed=`true`\n\n\n###### foreach, collect, take, count\n\n#### dependencies\n> collapsed=`true`\n\n\n##### Narrow\n\n##### Shuffle\n> collapsed=`true`\n\n\n###### handle\n> collapsed=`true`\n\n\n####### SortShuffleManager\n> collapsed=`true`\n\n\n######## Writer\n\n######## Reader\n\n###### mapSideCombine\n\n###### aggrator\n\n###### Serializer\n\n###### keyOrdering\n\n###### RDD\n\n#### 面向RDD\n> collapsed=`true`\n\n\n##### iterator 是模板方法\n> collapsed=`true`\n\n\n###### persist 中去查找有没有存过数据\n\n###### checkpoint\n> collapsed=`true`\n\n\n####### 从 HDFS 中取数据\n\n###### compute\n> collapsed=`true`\n\n\n####### HadoopRDD\n> collapsed=`true`\n\n\n######## 对文件包装成 iter\n\n####### ShuffleRDD\n> collapsed=`true`\n\n\n######## 调用了 Shuffle\\-Reader\n\n##### 是一个单向链表\n> collapsed=`true`\n\n\n###### lineage\n> collapsed=`true`\n\n\n####### 血统\n\n###### Pipline\n> collapsed=`true`\n\n\n####### iterator 的嵌套迭代引用\n\n####### 在一个 Task 中\n\n## 源码\n> collapsed=`true`\n\n\n### 基于 Standalone\n> collapsed=`true`\n\n\n#### 资源层\n> collapsed=`true`\n\n\n##### 角色\n> collapsed=`true`\n\n\n###### Master\n> collapsed=`true`\n\n\n####### 接受 Worker 的注册、资源的整理\n\n####### 接受计算层的资源申请\n> collapsed=`true`\n\n\n######## Driver\n\n######## Executor\n> collapsed=`true`\n\n\n######### registerApplication\n\n###### Workers\n> collapsed=`true`\n\n\n####### 启动计算层角色\n\n####### 向 Master 汇报资源使用\n\n##### RPC\n> collapsed=`true`\n\n\n###### Endpoint\n> collapsed=`true`\n\n\n####### ref\n\n####### send、ask\n\n####### receive、receiveAndReplay\n\n###### Dispatcher\n\n###### Netty\n\n#### 计算层\n> collapsed=`true`\n\n\n##### Client、Cluster\n> collapsed=`true`\n\n\n###### Driver 在哪里 ?\n> collapsed=`true`\n\n\n####### 什么是 Driver\n> collapsed=`true`\n\n\n######## SparkContext\n\n######## 就是我们自己的逻辑实现 \n\n##### Cluster\n> collapsed=`true`\n\n\n###### 1\\.Client\n> collapsed=`true`\n\n\n####### 通过资源层申请 Driver \n\n###### 2\\.Driver\n> collapsed=`true`\n\n\n####### SparkContext\n> collapsed=`true`\n\n\n######## backend\n> collapsed=`true`\n\n\n######### DriverEndpoint\n\n######### appClient\n> collapsed=`true`\n\n\n########## 去资源层的 Master 注册\n> collapsed=`true`\n\n\n########### 在 Master 中触发资源调度\n> collapsed=`true`\n\n\n############ 产生 Executor\n\n###### 3\\.ExecutorBackEnd\n> collapsed=`true`\n\n\n####### 向 Driver 反向注册\n\n####### Executor\n> collapsed=`true`\n\n\n######## threadPoll\n> collapsed=`true`\n\n\n######### task\n\n##### 任务调度执行\n> collapsed=`true`\n\n\n###### 1\\.RDD 的 Action 算子\n> collapsed=`true`\n\n\n####### sc\\.runJob\\(\\)\n\n###### 2\\.DAGScheduler\n> collapsed=`true`\n\n\n####### 是把 Job 的最后一个 RDD 作为参数\n\n####### Stage\n> collapsed=`true`\n\n\n######## 最后一个 RDD 代表最后一个 Stage\n> collapsed=`true`\n\n\n######### Stage 中只有一个 RDD\n\n####### 递归\\-遍历\n> collapsed=`true`\n\n\n######## 递归\n> collapsed=`true`\n\n\n######### 以 Stage 换言之以 ShuffleDep 为边界\n\n######## 遍历\n> collapsed=`true`\n\n\n######### 寻找 ShuffleDep 的过程是触发的遍历\n\n####### 回归过程中触发 task 调度提交\n\n####### Stage\n> collapsed=`true`\n\n\n######## task 的数量是最后一个 RDD 的分区数量\n\n######## 最佳计算位置\n\n######## Stage 会产生一个 taskBinary, 并广播出去\n\n######## 一个 Stage 根据分区数, 产生对应的 task\n\n######## 最终将 tasks 填充到 TaskSet\n> collapsed=`true`\n\n\n######### 触发 TaskScheduler\n\n###### 3\\.TaskScheduler\n> collapsed=`true`\n\n\n####### schdduleMode\n> collapsed=`true`\n\n\n######## FIFO\n\n######## Pair\n\n####### TaskSetManager\n\n###### 4\\.Executor\n> collapsed=`true`\n\n\n####### runTask\n> collapsed=`true`\n\n\n######## SparkEnv\n> collapsed=`true`\n\n\n######### MemoryManager\n> collapsed=`true`\n\n\n########## ExecutionMemory\n\n########## memoryStore\n\n######### BlockManager\n\n######### MapOutputTracker\n\n######### NettyBlockTransferService\n\n######## Task\n> collapsed=`true`\n\n\n######### 1\\.输入\n> collapsed=`true`\n\n\n########## HadoopRDD\n\n########## Persist\n\n########## checkpoint\n\n########## Shuffle\\-Reader\n\n######### 2\\.计算\n> collapsed=`true`\n\n\n########## Pipline : iter\n\n######### 3\\.输出\n> collapsed=`true`\n\n\n########## Shuffle\\-Writer\n\n########## Result\n\n######## SortShuffleManager\n> collapsed=`true`\n\n\n######### registerHandle\n\n######### getWriter\n> collapsed=`true`\n\n\n########## BypassMergeSortShuffleWriter\n\n########## BaseShuffleHandle\n> collapsed=`true`\n\n\n########### map\n\n########### buffer\n\n########## UnsafeShuffleWriter\n\n######### getReader\n> collapsed=`true`\n\n\n########## dep\n> collapsed=`true`\n\n\n########### iter\n\n######## BlockManager\n> collapsed=`true`\n\n\n######### Shuffle\\-Witer\n> collapsed=`true`\n\n\n########## Disk\n\n######### persist\n> collapsed=`true`\n\n\n########## StorageLevel\n> collapsed=`true`\n\n\n########### MemoryOnly\n\n########### MemoryAndDisk\n\n########### Serializer\n\n######### broadcast\n\n######## TaskMemoryManager\n> collapsed=`true`\n\n\n######### 每 Task 一个\n\n######### 计算过程中\n> collapsed=`true`\n\n\n########## Shuffle\\-Writer\n> collapsed=`true`\n\n\n########### UnsafeShuffleWriter\n\n########### BaseShuffleHandle\n\n########### 计算过程中的缓冲区\n",
  "content_size": 6769,
  "collected_at": "2026-02-06T02:07:55.964219",
  "compilation_status": "failed",
  "compilation_error": "[WinError 2] 系统找不到指定的文件。",
  "license": "none",
  "license_name": "No License",
  "license_url": "",
  "repo_stars": 0,
  "repo_forks": 0,
  "repo_owner": "40Eqiuhouru",
  "repo_name": "SparkSystem",
  "repo_description": "Learn and use Spark at work",
  "repo_language": "Scala",
  "repo_topics": [],
  "repo_created_at": "2025-05-21T15:53:09Z",
  "repo_updated_at": "2025-05-21T16:27:15Z"
}