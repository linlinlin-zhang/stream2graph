{
  "id": "gh_sequence_00628",
  "source": "github",
  "source_url": "https://github.com/DiscoLucas/P8-Project/blob/b379ef87e0f2bd50d129288d5f398512846df89a/Dataprocessing%20Pipeline/pain.mmd",
  "github_repo": "DiscoLucas/P8-Project",
  "github_file_path": "Dataprocessing Pipeline/pain.mmd",
  "diagram_type": "sequence",
  "code": "sequenceDiagram\n    participant Notebook as Notebook Execution\n    participant MainBlock as Main Processing Block\n    participant proc_subj_data as process_subject_data()\n    participant extract_xdf as extract_bvp_and_markers_from_xdf()\n    participant pyxdf as pyxdf.load_xdf()\n    participant get_hrv as get_hrv_metrics()\n    participant filter_bvp as filter_bvp()\n    participant scipy as scipy.signal\n    participant heartpy as heartpy.process()\n    participant neurokit as neurokit2.hrv()\n    participant pd as pandas\n    participant statsmodels as statsmodels.mixedlm()\n\n    Notebook->>MainBlock: Start data processing\n    MainBlock->>MainBlock: Iterate session_folders (os.scandir)\n    loop For each session_folder\n        MainBlock->>MainBlock: Iterate subject_folders_map (os.scandir, re.search)\n        loop For each subject_id\n            MainBlock->>MainBlock: Find baseline_filepath & task_filepath (glob.glob)\n            alt baseline_filepath AND task_filepath exist\n                MainBlock->>proc_subj_data: Call(subject_id, baseline_filepath, task_filepath)\n                \n                proc_subj_data->>proc_subj_data: Determine condition\n                \n                %% Baseline Processing\n                proc_subj_data->>extract_xdf: Call(baseline_filepath)\n                extract_xdf->>pyxdf: load_xdf(baseline_filepath)\n                pyxdf-->>extract_xdf: streams, header\n                extract_xdf-->>proc_subj_data: bvp_baseline, ts_baseline, ...\n                \n                alt bvp_baseline data exists\n                    proc_subj_data->>get_hrv: Call(bvp_baseline, ts_baseline, fs)\n                    get_hrv->>filter_bvp: Call(bvp_baseline, fs)\n                    filter_bvp->>scipy: butter()\n                    scipy-->>filter_bvp: filter_coeffs (b,a)\n                    filter_bvp->>scipy: filtfilt(coeffs, bvp_baseline)\n                    scipy-->>filter_bvp: filtered_signal\n                    filter_bvp-->>get_hrv: filtered_bvp_baseline\n                    get_hrv->>heartpy: process(filtered_bvp_baseline, fs)\n                    heartpy-->>get_hrv: wd, m (peaks)\n                    get_hrv->>neurokit: hrv(ibi_ms, ...)\n                    neurokit-->>get_hrv: hrv_indices\n                    get_hrv-->>proc_subj_data: baseline_hrv_metrics\n                    proc_subj_data->>proc_subj_data: Store baseline_hrv_metrics\n                else No baseline BVP\n                    proc_subj_data->>proc_subj_data: Log warning\n                end\n\n                %% Task Processing\n                proc_subj_data->>extract_xdf: Call(task_filepath)\n                extract_xdf->>pyxdf: load_xdf(task_filepath)\n                pyxdf-->>extract_xdf: streams, header\n                extract_xdf-->>proc_subj_data: bvp_task, ts_task, ...\n\n                alt bvp_task data exists\n                    proc_subj_data->>get_hrv: Call(bvp_task, ts_task, fs)\n                    get_hrv->>filter_bvp: Call(bvp_task, fs)\n                    filter_bvp->>scipy: butter()\n                    scipy-->>filter_bvp: filter_coeffs (b,a)\n                    filter_bvp->>scipy: filtfilt(coeffs, bvp_task)\n                    scipy-->>filter_bvp: filtered_signal\n                    filter_bvp-->>get_hrv: filtered_bvp_task\n                    get_hrv->>heartpy: process(filtered_bvp_task, fs)\n                    heartpy-->>get_hrv: wd, m (peaks)\n                    get_hrv->>neurokit: hrv(ibi_ms, ...)\n                    neurokit-->>get_hrv: hrv_indices\n                    get_hrv-->>proc_subj_data: task_hrv_metrics\n                    proc_subj_data->>proc_subj_data: Store task_hrv_metrics\n                else No task BVP\n                    proc_subj_data->>proc_subj_data: Log warning\n                end\n                \n                proc_subj_data->>pd: pd.DataFrame(results_list)\n                pd-->>proc_subj_data: subject_hrv_df\n                proc_subj_data-->>MainBlock: subject_hrv_df\n                MainBlock->>MainBlock: Append subject_hrv_df to all_participant_dfs\n            else Missing files\n                MainBlock->>MainBlock: Log skipping subject\n            end\n        end\n    end\n    \n    alt all_participant_dfs is not empty\n        MainBlock->>pd: pd.concat(all_participant_dfs)\n        pd-->>MainBlock: final_df\n    else\n        MainBlock->>pd: pd.DataFrame() (empty)\n        pd-->>MainBlock: final_df (empty)\n    end\n    MainBlock-->>Notebook: final_df\n\n    %% Statistical Modeling Phase\n    Notebook->>Notebook: Check final_df for validity\n    alt final_df is valid and has HRV_RMSSD\n        Notebook->>Notebook: Prepare model_df (dropna, astype)\n        Notebook->>statsmodels: mixedlm(\"HRV_RMSSD ~ C(Phase)*C(Condition)\", model_df, groups=\"ParticipantID\")\n        statsmodels-->>Notebook: model_lmm\n        Notebook->>model_lmm: fit()\n        model_lmm-->>Notebook: result_lmm\n        Notebook->>result_lmm: summary()\n        result_lmm-->>Notebook: Print summary\n    else final_df is not valid\n        Notebook->>Notebook: Print \"Skipping statistical analysis\"\n    end",
  "content_size": 5058,
  "collected_at": "2026-02-06T01:34:57.597472",
  "compilation_status": "failed",
  "license": "mit",
  "license_name": "MIT License",
  "license_url": "https://api.github.com/licenses/mit",
  "repo_stars": 0,
  "repo_forks": 0,
  "compilation_error": "[WinError 2] 系统找不到指定的文件。"
}