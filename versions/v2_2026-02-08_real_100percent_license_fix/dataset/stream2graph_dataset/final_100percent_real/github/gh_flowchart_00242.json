{
  "id": "gh_flowchart_00242",
  "source": "github",
  "source_url": "https://github.com/bymarcelolewin/care-assistant/blob/4fe93a65820e7393e8d177305f964ef2e6664fac/.cody/project/library/docs/v0.9.0-agent-workflow.mmd",
  "github_repo": "bymarcelolewin/care-assistant",
  "github_file_path": ".cody/project/library/docs/v0.9.0-agent-workflow.mmd",
  "diagram_type": "flowchart",
  "code": "---\ntitle: CARE Assistant v0.9.0 - Complete Agent Workflow\ndescription: Comprehensive LangGraph workflow showing all nodes, edges, and decision points from initial greeting to final response. Built on LangChain 1.0.2 and LangGraph 1.0.1 (stable releases).\nversion: 0.9.0\ndate: 2025-10-21\ntech_stack: Python 3.13 | LangChain 1.0.2 | LangGraph 1.0.1 | Ollama\n---\n\nflowchart TB\n    Start([START]) --> IdentifyUser[identify_user Node]\n\n    %% Node 1: Identify User - Initial Greeting or Already Identified\n    IdentifyUser --> CheckUserID{user_id exists?}\n\n    %% Branch 1A: User Already Identified\n    CheckUserID -->|Yes| AlreadyIdentified[Log: User already identified]\n    AlreadyIdentified --> CheckFirstGreeting{first_greeting flag?}\n\n    %% Branch 1B: User NOT Identified - Need Name\n    CheckUserID -->|No| CheckMessages{messages.length == 0?}\n\n    %% First Interaction - No messages yet\n    CheckMessages -->|Yes| AskName1[\"Send: Hello! I'm your ‚ù§Ô∏è CARE Assistant.<br/>What's your name?\"]\n    AskName1 --> End1([END - Wait for user input])\n\n    %% Has messages - Check if greeted\n    CheckMessages -->|No| CheckGreeted{Already asked<br/>for name?}\n\n    %% Haven't greeted yet\n    CheckGreeted -->|No| AskName2[\"Send: Hello! I'm your ‚ù§Ô∏è CARE Assistant.<br/>What's your name?\"]\n    AskName2 --> End2([END - Wait for user input])\n\n    %% Already greeted - Extract name from response\n    CheckGreeted -->|Yes| ExtractName[\"LLM: Extract name from user input<br/>(with_structured_output using NameExtraction model)\"]\n    ExtractName --> CheckConfidence{Confidence == 'high'<br/>AND name extracted?}\n\n    %% Low confidence - Ask again\n    CheckConfidence -->|No| RetryName[\"Send: I didn't quite catch your name.<br/>Could you please tell me your first name?\"]\n    RetryName --> End3([END - Wait for user input])\n\n    %% High confidence - Search user\n    CheckConfidence -->|Yes| SearchUser[Search user_profiles.json<br/>by extracted name<br/>case-insensitive]\n    SearchUser --> UserFound{User found?}\n\n    %% User not found\n    UserFound -->|No| NotFound[\"Send: Sorry [name], you are not<br/>in our system. Please contact support.\"]\n    NotFound --> End4([END - Conversation complete])\n\n    %% User found - Load profile and welcome\n    UserFound -->|Yes| LoadProfile[\"Load user profile:<br/>- user_id<br/>- user_profile<br/>- member_since\"]\n    LoadProfile --> FormatDate[\"Format member_since date<br/>(e.g., 'March 2022')\"]\n    FormatDate --> SendWelcome[\"Send: Welcome [FirstName]! ‚ù§Ô∏è<br/>Thank you for being a member since [Date].<br/>Do you have any questions about<br/>your plan, benefits, or claims?\"]\n    SendWelcome --> SetFirstGreeting[\"Set first_greeting = True\"]\n    SetFirstGreeting --> StateUpdate1[\"üìä STATE UPDATED:<br/>‚úì user_id<br/>‚úì user_profile<br/>‚úì messages<br/>‚úì first_greeting<br/>‚úì execution_trace\"]\n    StateUpdate1 --> End5([END - Wait for user question])\n\n    %% Conditional Edge: should_continue_after_identify\n    CheckFirstGreeting -->|Yes<br/>first_greeting = True| End6([END - Show welcome only])\n    CheckFirstGreeting -->|No<br/>User asks question| ClearFirstGreeting[\"Clear first_greeting flag<br/>(happens implicitly on next turn)\"]\n    ClearFirstGreeting --> OrchestrateTools\n\n    %% Node 2: Orchestrate Tools - LLM-based multi-tool coordination\n    OrchestrateTools[\"orchestrate_tools Node<br/>(LLM-based tool selection)\"]\n    OrchestrateTools --> GetUserQuestion[\"Get user's latest message\"]\n    GetUserQuestion --> LLMOrchestrator[\"LLM: Analyze question and determine tools to call<br/><br/>Prompt includes:<br/>- User's question<br/>- Available tools (coverage_lookup, benefit_verify, claims_status)<br/>- Examples of tool selection<br/><br/>LLM returns plain text list of tool names\"]\n\n    LLMOrchestrator --> ParseToolNames[\"Parse LLM response:<br/>For each line, check if it contains<br/>'coverage_lookup', 'benefit_verify', or 'claims_status'<br/>Build list of tool names (removes duplicates)\"]\n    ParseToolNames --> HasTools{Tools<br/>identified?}\n\n    %% No tools needed (general conversation)\n    HasTools -->|No| NoTools[\"No tools needed<br/>Log: Question doesn't need tools\"]\n    NoTools --> GenerateResponse\n\n    %% Tools identified - Execute them\n    HasTools -->|Yes| InitResults[\"Initialize tool_results = {}<br/>(or get existing from state)\"]\n    InitResults --> ToolLoop[\"For each tool in list:\"]\n\n    %% Tool Execution Loop\n    ToolLoop --> CheckToolType{Tool type?}\n\n    CheckToolType -->|coverage_lookup| Tool1[\"Execute coverage_lookup.invoke:<br/>Args: {user_id, query}<br/>Returns: plan details, deductible, limits\"]\n    Tool1 --> StoreResult1[\"Store in tool_results['coverage_lookup']\"]\n    StoreResult1 --> Progress1[\"Add to progress_messages:<br/>'Let me check your coverage details...'\"]\n    Progress1 --> MoreTools1{More tools?}\n\n    CheckToolType -->|benefit_verify| Tool2[\"Execute benefit_verify.invoke:<br/>Args: {user_id, query, service_type='general medical'}<br/>Returns: service coverage details\"]\n    Tool2 --> StoreResult2[\"Store in tool_results['benefit_verify']\"]\n    StoreResult2 --> Progress2[\"Add to progress_messages:<br/>'Now let me verify what benefits are covered...'\"]\n    Progress2 --> MoreTools1\n\n    CheckToolType -->|claims_status| Tool3[\"Execute claims_status.invoke:<br/>Args: {user_id, query}<br/>Returns: claims history and status\"]\n    Tool3 --> StoreResult3[\"Store in tool_results['claims_status']\"]\n    StoreResult3 --> Progress3[\"Add to progress_messages:<br/>'Let me look up your claims history...'\"]\n    Progress3 --> MoreTools1\n\n    MoreTools1 -->|Yes| ToolLoop\n    MoreTools1 -->|No| AllToolsComplete[\"All tools executed<br/>Set needs_tool_call = False\"]\n    AllToolsComplete --> StateUpdate2[\"üìä STATE UPDATED:<br/>‚úì tool_results (dict with all results)<br/>‚úì progress_messages (for UI 'thinking' indicators)<br/>‚úì needs_tool_call = False<br/>‚úì execution_trace\"]\n    StateUpdate2 --> GenerateResponse\n\n    %% Node 3: Generate Response - Synthesize answer with LLM\n    GenerateResponse[\"generate_response Node<br/>(Natural language synthesis)\"]\n    GenerateResponse --> BuildContext[\"Build LLM context:<br/>- User profile details (name, age, plan, deductible, etc.)<br/>- Conversation history (all messages)<br/>- Tool results (if any exist in state)\"]\n\n    BuildContext --> SystemPrompt[\"Create system prompt:<br/>'You are a helpful insurance assistant...<br/>Use ONLY provided information.<br/>Be conversational and friendly.'\"]\n\n    SystemPrompt --> AddToolResults{tool_results exist?}\n    AddToolResults -->|Yes| FormatToolResults[\"Format tool results for LLM:<br/>For each tool_name: result<br/>Add formatted context to system prompt\"]\n    AddToolResults -->|No| SkipToolResults[Skip tool context]\n\n    FormatToolResults --> CallLLM\n    SkipToolResults --> CallLLM\n\n    CallLLM[\"LLM: Generate conversational response<br/>using system prompt + full context + conversation history\"]\n    CallLLM --> ResponseSuccess{Success?}\n\n    %% Error handling\n    ResponseSuccess -->|Error| ErrorResponse[\"Send: I'm sorry, I encountered an error.<br/>Could you please rephrase your question?\"]\n    ErrorResponse --> StateUpdate3Error\n\n    %% Success - Return response (v0.4.0+: tool_results NOT cleared)\n    ResponseSuccess -->|Yes| ReturnResponse[\"Return AI response message\"]\n    ReturnResponse --> StateUpdate3[\"üìä STATE UPDATED:<br/>‚úì messages (response appended via add_messages reducer)<br/>‚úì execution_trace<br/><br/>NOTE: tool_results PERSIST in state<br/>(v0.4.0+ fix for frontend observability)\"]\n\n    StateUpdate3Error[\"üìä STATE UPDATED:<br/>‚úì messages (error message)<br/>‚úì execution_trace\"]\n    StateUpdate3Error --> End7\n\n    StateUpdate3 --> End7([END - Turn complete])\n\n    %% Styling\n    classDef startEnd fill:#10b981,stroke:#059669,stroke-width:3px,color:#fff\n    classDef nodeStyle fill:#0ea5e9,stroke:#0284c7,stroke-width:2px,color:#fff\n    classDef decisionStyle fill:#f59e0b,stroke:#d97706,stroke-width:2px,color:#fff\n    classDef toolStyle fill:#8b5cf6,stroke:#7c3aed,stroke-width:2px,color:#fff\n    classDef llmStyle fill:#ec4899,stroke:#db2777,stroke-width:2px,color:#fff\n    classDef endStyle fill:#ef4444,stroke:#dc2626,stroke-width:3px,color:#fff\n\n    classDef stateStyle fill:#22c55e,stroke:#16a34a,stroke-width:2px,color:#fff,stroke-dasharray: 5 5\n\n    class Start,End1,End2,End3,End4,End5,End6,End7 startEnd\n    class IdentifyUser,OrchestrateTools,GenerateResponse nodeStyle\n    class CheckUserID,CheckMessages,CheckGreeted,CheckConfidence,UserFound,CheckFirstGreeting,HasTools,CheckToolType,MoreTools1,AddToolResults,ResponseSuccess decisionStyle\n    class Tool1,Tool2,Tool3,StoreResult1,StoreResult2,StoreResult3 toolStyle\n    class ExtractName,LLMOrchestrator,CallLLM llmStyle\n    class StateUpdate1,StateUpdate2,StateUpdate3,StateUpdate3Error stateStyle\n",
  "content_size": 8777,
  "collected_at": "2026-02-06T01:42:53.038156",
  "compilation_status": "failed",
  "license": "none",
  "license_name": "No License",
  "license_url": "",
  "repo_stars": 0,
  "repo_forks": 0,
  "compilation_error": "[WinError 2] Á≥ªÁªüÊâæ‰∏çÂà∞ÊåáÂÆöÁöÑÊñá‰ª∂„ÄÇ"
}