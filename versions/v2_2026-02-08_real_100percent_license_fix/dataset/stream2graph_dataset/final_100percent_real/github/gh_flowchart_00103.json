{
  "id": "gh_flowchart_00103",
  "source": "github",
  "source_url": "https://github.com/lucasgaldinos/Routing_data/blob/0e55b8cd78ebb2bbc710dad8a5f38e917ee2d821/docs/diagrams/converter-architecture.mmd",
  "github_repo": "lucasgaldinos/Routing_data",
  "github_file_path": "docs/diagrams/converter-architecture.mmd",
  "diagram_type": "flowchart",
  "code": "---\nconfig:\n  layout: elk\n  theme: forest\n  elk:\n    mergeEdges: true\n    nodePlacementStrategy: BRANDES_KOEPF\n    nodeSpacing: 50\n  themeVariables:\n    primaryColor: '#e8f5e8'\n    primaryTextColor: '#1b5e20'\n    primaryBorderColor: '#2e7d32'\n    lineColor: '#4caf50'\n    fontFamily: arial\n    fontSize: 12px\n    background: '#f9fff9'\n  flowchart:\n    defaultRenderer: elk\n    htmlLabels: true\n    curve: basis\n    useMaxWidth: true\n    diagramPadding: 20\ntitle: TSPLIB95 to JSON/DuckDB Converter Architecture\n---\nflowchart TB\n    subgraph input[\"Input Layer\"]\n        raw[\"datasets_raw/problems/<br/>{tsp,vrp,atsp,hcp,sop,tour}/\"]\n        files[\"*.tsp, *.vrp, *.atsp,<br/>*.hcp, *.sop, *.tour\"]\n    end\n    \n    subgraph core[\"Core Processing Layer\"]\n        subgraph scanner_detail[\"File Scanner (src/converter/core/scanner.py)\"]\n            scan_walk[\"Directory Walker<br/>- Recursive traversal<br/>- File filtering<br/>- Path resolution\"]\n            scan_detect[\"Type Detector<br/>- Extension analysis<br/>- Content validation<br/>- Format classification\"]\n            scan_batch[\"Batch Manager<br/>- Parallel processing<br/>- Progress tracking<br/>- Error aggregation\"]\n        end\n        \n        subgraph parser_detail[\"TSPLIB95 Parser (src/converter/core/parser.py)\"]\n            parse_tsp[\"TSPLib95 Wrapper<br/>- loaders.load() integration<br/>- StandardProblem handling<br/>- Special distance functions\"]\n            parse_valid[\"Data Validator<br/>- Schema validation<br/>- Range checking<br/>- Consistency verification\"]\n            parse_error[\"Error Handler<br/>- Parsing exceptions<br/>- Recovery strategies<br/>- Detailed logging\"]\n        end\n        \n        subgraph transform_detail[\"Data Transformer (src/converter/core/transformer.py)\"]\n            trans_extract[\"Data Extractor<br/>- Node coordinates<br/>- Edge weights<br/>- Problem metadata\"]\n            trans_norm[\"Normalizer<br/>- Index standardization<br/>- Unit conversion<br/>- Data cleaning\"]\n            trans_format[\"Format Converter<br/>- JSON serialization<br/>- Database mapping<br/>- Type conversion\"]\n        end\n    end\n    \n    subgraph database[\"Database Layer\"]\n        subgraph schema_detail[\"Schema Management (src/converter/database/schema.py)\"]\n            schema_def[\"Schema Definition<br/>- Table creation<br/>- Index management<br/>- Constraint validation\"]\n            schema_mig[\"Migration System<br/>- Version tracking<br/>- Schema updates<br/>- Data migration\"]\n        end\n        \n        subgraph crud_detail[\"CRUD Operations (src/converter/database/operations.py)\"]\n            crud_insert[\"Bulk Insert<br/>- Prepared statements<br/>- Batch processing<br/>- Transaction handling\"]\n            crud_update[\"Update Manager<br/>- Conflict resolution<br/>- Incremental updates<br/>- Change detection\"]\n            crud_query[\"Query Engine<br/>- Analysis functions<br/>- Statistics<br/>- Data export\"]\n        end\n    end\n    \n    subgraph output[\"Output Layer\"]\n        subgraph json_detail[\"JSON Writer (src/converter/output/json_writer.py)\"]\n            json_format[\"Format Manager<br/>- Flattened structure<br/>- Schema validation<br/>- Pretty printing\"]\n            json_file[\"File Manager<br/>- Directory creation<br/>- Naming conventions<br/>- Compression options\"]\n        end\n        \n        subgraph db_detail[\"DuckDB Interface (src/converter/database/models.py)\"]\n            db_conn[\"Connection Pool<br/>- Thread safety<br/>- Connection reuse<br/>- Resource management\"]\n            db_opt[\"Query Optimizer<br/>- Index usage<br/>- Join optimization<br/>- Performance tuning\"]\n        end\n    end\n    \n    raw --> scan_walk\n    files --> scan_detect\n    scan_walk --> scan_batch\n    scan_detect --> scan_batch\n    scan_batch --> parse_tsp\n    parse_tsp --> parse_valid\n    parse_valid --> parse_error\n    parse_error --> trans_extract\n    trans_extract --> trans_norm\n    trans_norm --> trans_format\n    trans_format --> json_format\n    trans_format --> schema_def\n    json_format --> json_file\n    schema_def --> schema_mig\n    schema_mig --> crud_insert\n    crud_insert --> crud_update\n    crud_update --> crud_query\n    crud_query --> db_conn\n    db_conn --> db_opt\n    \n    classDef input fill:#e3f2fd,stroke:#1976d2,stroke-width:2px\n    classDef scanner fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    classDef parser fill:#e8f5e8,stroke:#388e3c,stroke-width:2px\n    classDef transform fill:#fff3e0,stroke:#f57c00,stroke-width:2px\n    classDef schema fill:#fce4ec,stroke:#c2185b,stroke-width:2px\n    classDef crud fill:#e1f5fe,stroke:#0277bd,stroke-width:2px\n    classDef json fill:#f1f8e9,stroke:#689f38,stroke-width:2px\n    classDef database fill:#fff8e1,stroke:#fbc02d,stroke-width:2px\n    \n    class raw,files input\n    class scan_walk,scan_detect,scan_batch scanner\n    class parse_tsp,parse_valid,parse_error parser\n    class trans_extract,trans_norm,trans_format transform\n    class schema_def,schema_mig schema\n    class crud_insert,crud_update,crud_query crud\n    class json_format,json_file json\n    class db_conn,db_opt database",
  "content_size": 5062,
  "collected_at": "2026-02-06T01:41:57.806557",
  "compilation_status": "failed",
  "license": "none",
  "license_name": "No License",
  "license_url": "",
  "repo_stars": 0,
  "repo_forks": 0,
  "compilation_error": "[WinError 2] 系统找不到指定的文件。"
}