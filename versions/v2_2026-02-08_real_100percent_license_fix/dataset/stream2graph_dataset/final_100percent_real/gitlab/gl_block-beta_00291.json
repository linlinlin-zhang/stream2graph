{
  "id": "gl_block-beta_00291",
  "source": "gitlab",
  "source_url": "https://github.com/Chrouos/RAG-base-Automatic-Peer-Review/blob/aa1865aded18fdbbdfa055f0cf4f18537243e450/dataset/SEA_ICLR_2024/GPT4_consolidated_reviews_2k/e0bdvNsgcF.mmd",
  "source_note": "collected_from_github_additional",
  "github_repo": "Chrouos/RAG-base-Automatic-Peer-Review",
  "diagram_type": "block-beta",
  "code": "**Summary:**\nThe paper explores an algorithm to identify the largest and smallest elements in tensors represented in a low-rank format, specifically in exact CP decomposition. It proposes an alternating iterative method enhanced by a maximum block increasing approach and a novel block-search strategy. The methodology is validated through theoretical analysis and numerical experiments which demonstrate its improvements in accuracy and efficiency over previous methods. However, the paper is criticized for lack of rigorous convergence analysis, potential obfuscation of technical oversights, and insufficient novelty in advancing beyond existing methods.\n\n**Strengths:**\n- The paper introduces a novel continuous optimization model for identifying the largest or smallest elements in tensor data using low-rank formats such as CP, Tucker, and TT. This approach distinguishes itself from existing methods and showcases versatility across multiple tensor formats.\n- Demonstrated improvements in accuracy and computational efficiency are reported through numerical experiments, suggesting practical utility in real-world applications.\n- The clarity and structure of the paper are commendable, with consistent use of precise mathematical notations that aid in understanding the proposed methods and their theoretical underpinnings.\n- Several results showcase good performance in specific scenarios like searching for CP-tensors' minima.\n\n**Weaknesses:**\n- The theoretical analysis provided in the paper lacks depth, particularly in exploring the number of minimizers for the formulated optimization problems and the convergence aspects of the entire sequence to the optimal solution.\n- The proof of critical theorems, particularly Theorem 1, appears incomplete or incorrect, with some concerns about the relevance and precision of the symmetric tensor eigenvalue problem's formulation when using different factor matrices.\n- There is a limited discussion on novelty and differentiation of the proposed methods from existing techniques. More thorough comparative analysis would strengthen the paper’s contributions.\n- Potential impacts and applications beyond the niche area of low-rank tensors are not sufficiently discussed, limiting broader relevance to the machine learning community.\n- Lack of code availability hinders reproducibility and practical assessment of the proposed algorithms outside the paper's context.\n- The paper has inadequately discussed the limitations or challenges associated with deploying the proposed algorithm in realistic settings. A comprehensive examination of these factors is essential for practical applicability.\n\n**Questions:**\n- Can the authors provide a more detailed explanation of how your proposed algorithms significantly differ from existing methods in both conceptual and theoretical aspects? Are there specific aspects of your approach that are novel and distinct from prior work?\n- Could the authors elaborate on potential applications or extensions of your method beyond the specific task of low-rank tensors? What are the limitations of your method in terms of scalability or adaptability to different problem domains?\n- Have experiments on model functions other than Rastrigin and Schwefel been conducted?\n- Have trials been performed to assess the scalability of the method to significantly higher dimensions (e.g., N=100, 1000), which could help understand its potential in overcoming the curse of dimensionality?\n- In reference to your Theorems and proof structures, especially Theorem 1, what ensures the equivalence or correction of the proofs provided? Can the authors clarify the issues raised about the symmetric tensor eigenvalue problem and the proof's precision in its current state?\n\n**Soundness:**\n2 fair\n\n**Presentation:**\n2 fair\n\n**Contribution:**\n1 poor\n\n**Rating:**\n2 reject, significant issues present\n\n**Paper Decision:**\n- Decision: Reject\n- Reasons: The paper, though presenting a novel approach for identifying elements in tensor decompositions, suffers from several critical issues. The convergence analysis is not sufficiently rigorous, and there are significant oversights and technical flaws noted in theorem formulations and proofs. Such errors undermine the reliability of the proposed methods. Additionally, the contribution of the paper is viewed as minimal, not significantly advancing existing knowledge or methods. The issues outlined lead to the decision to reject the paper, as it does not meet the required standards for soundness and contribution.",
  "content_size": 4533,
  "collected_at": "2026-02-06T14:06:19.737755",
  "compilation_status": "failed",
  "compilation_error": "[WinError 2] 系统找不到指定的文件。",
  "license": "gitlab_repo",
  "license_name": "GitLab Repository",
  "license_url": "https://gitlab.com"
}