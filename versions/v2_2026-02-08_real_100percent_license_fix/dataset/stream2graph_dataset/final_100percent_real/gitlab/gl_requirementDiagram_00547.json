{
  "id": "gl_requirementDiagram_00547",
  "source": "gitlab",
  "source_url": "https://github.com/Fireblossom/EditTrans/blob/680e0dd28f662d00b86e658cc7e3bab64f0dafe1/data/rainbow_bank/mmd_olmocr/2307.03181_7.mmd",
  "source_note": "collected_from_github_additional",
  "github_repo": "Fireblossom/EditTrans",
  "diagram_type": "requirementDiagram",
  "code": "Krishnamurthy Iyer Haifeng Xu You Zu \n\nwhere \\(e_{h}\\) is the distribution that puts all its weight on \\(h=(\\dots,x_{-2},x_{-1})\\in\\mathcal{X}^{\\infty}\\), and ehâŠ—p(â‹…|xâˆ’1)encodes the fact that the receiversâ€™ belief about \\(\\bar{\\omega}_{t}\\)\\(\\bar{\\omega}_{t}\\) comes from the resulting Markovian transition p(â‹…|xâˆ’1). (Here, \\(\\mathbf{P}^{\\sigma}\\)denotes the probability measure induced by the signaling mechanism \\(\\sigma\\)together with the underlying Markovian dynamics, assuming that the receivers adopt the senderâ€™s recommendations.) When the preceding condition holds, we denote the resulting belief sequence \\(\\{\\phi_{t}:t\\in\\mathbb{Z}\\}\\) by \\(\\Phi_{\\mathsf{full}}\\) and call it the _ full-history information model_ . \n\n\n2.** No-history information model:**  At the other extreme, consider the case where the receivers have no information about the history of the process. Then, at any time \\(t\\), the receiverâ€™s belief \\(\\phi_{t}\\)must be independent of the realized history. A natural approach, motivated by the requirement of consistency, 2 2  In certain cases, this modeling assumption can be established formally. For instance, if time periods denote the Poisson arrival times of receivers to a stochastic system, then the receivers observe the system distributed as the time-average [ Wolff ,  1982 ], which equals the expectation w.r.t. the invariant distribution when the latter is unique. is to let each belief \\(\\phi_{t}\\) equal the invariant distribution \\(\\mathsf{Inv}(\\sigma)\\). Specifically, we have for each \\(t\\in\\mathbb{Z}\\), \n\nğÏƒ(Ï•t=ğ–¨ğ—‡ğ—(Ïƒ)âŠ—P|hÂ¯t=h,Ï‰Â¯t=Ï‰)=1,for all hâˆˆğ’³âˆ and Ï‰âˆˆÎ©.  \n\nHere, \\(\\mathsf{Inv}(\\sigma)\\otimes P\\) encodes the distribution of \\((\\bar{h}_{t},\\bar{\\omega}_{t})\\) where the history \\(\\bar{h}_{t}\\)\\(\\bar{h}_{t}\\) is distributed as \\(\\mathsf{Inv}(\\sigma)\\), and the state \\(\\bar{\\omega}_{t}\\)\\(\\bar{\\omega}_{t}\\) is obtained from a subsequent transition from the Markov kernel \\(P\\). For the setting where the preceding condition holds, we denote the belief sequence \\(\\{\\phi_{t}:t\\in\\mathbb{Z}\\}\\) by \\(\\Phi_{\\mathsf{no}}\\)and call it the _ no-history information model_ . \n\n\n3.** Partial-history information models:**  Between the two extremes described above lie a multitude of information models where receivers possess partial information about the process history. In such partial-history models, the belief sequence \\(\\phi_{t}\\) would have a complex dependence on the history \\(\\bar{h}_{t}\\)\\(\\bar{h}_{t}\\). Although a comprehensive analysis of all such models is beyond the scope of this paper, we focus on a particular sequence of information models to capture realistic scenarios where the receivers may have some stale information about the process. 3 3  Such stale information about the process could plausibly arise from the receivers having interacted with the process in the past; however, we do not consider such repeated interactions in our model. \n\nSpecifically, for a fixed \\(\\ell\\geq 0\\), consider the setting where the receivers observe the process with an \\(\\ell\\)-period lag. In other words, at each time \\(t\\), the receiver observes the history \\(\\bar{h}_{t-\\ell}\\)\\(\\bar{h}_{t-\\ell}\\), i.e., all the state-action pairs before time \\(t-\\ell\\). Then, we have for each \\(t\\in\\mathbb{Z}\\), \n\nğÏƒ(Ï•t=ehâˆ’â„“âŠ—PÏƒâ„“âŠ—P|hÂ¯t=h,Ï‰Â¯t=Ï‰)=1,for all hâˆˆğ’³âˆ and Ï‰âˆˆÎ©.  \n\nHere, \\(e_{h_{-\\ell}}\\)is the distribution that puts all its weight on the realization \\(\\bar{h}_{t-\\ell}=h_{-\\ell}\\)\\(\\bar{h}_{t-\\ell}=h_{-\\ell}\\), \\(P_{\\sigma}^{\\ell}\\)encodes the subsequent \\(\\ell\\)transitions of the process, i.e., the distribution of \\((\\bar{x}_{t-\\ell},\\dots,\\bar{x}_{t-1})\\)\\((\\bar{x}_{t-\\ell},\\dots,\\bar{x}_{t-1})\\) under the signaling mechanism \\(\\sigma\\), and finally, the kernel \\(P\\) captures the subsequent distribution of the \\(\\bar{\\omega}_{t}\\)\\(\\bar{\\omega}_{t}\\). When the preceding holds, we denote the resulting belief sequence \\(\\{\\phi_{t}:t\\in\\mathbb{Z}\\}\\) as \\(\\Phi_{\\ell}\\), and call it the _ partial-history information model with lag_ \\(\\ell\\)_._  We note that \\(\\Phi_{0}\\) is same as the full-history information model \\(\\Phi_{\\mathsf{full}}\\). \n\nAn advantage of studying the sequence \\(\\{\\Phi_{\\ell}\\}_{\\ell\\geq 0}\\) of information models is that they serve as a standard of comparison for other more complex information models. In particular, one can show that the senderâ€™s payoff under the information model \\(\\Phi_{\\ell}\\)acts as a lower-bound on her payoff in settings where the receivers only have limited, but arbitrary, information about states and action \\(\\ell\\)periods and further back. Thus, while we do not capture all possible partial-history information models, our choice provides a lower bound of many other information models and gives insight into the problemâ€™s fundamental difficulty. ",
  "content_size": 4765,
  "collected_at": "2026-02-06T14:12:06.378039",
  "compilation_status": "failed",
  "compilation_error": "[WinError 2] ç³»ç»Ÿæ‰¾ä¸åˆ°æŒ‡å®šçš„æ–‡ä»¶ã€‚",
  "license": "gitlab_repo",
  "license_name": "GitLab Repository",
  "license_url": "https://gitlab.com"
}