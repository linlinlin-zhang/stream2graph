{
  "id": "gl_block-beta_00295",
  "source": "gitlab",
  "source_url": "https://github.com/Chrouos/RAG-base-Automatic-Peer-Review/blob/aa1865aded18fdbbdfa055f0cf4f18537243e450/dataset/ICLR%202024/Accept%20(poster)-standardization_review/rGFrRMBbOq.mmd",
  "source_note": "collected_from_github_additional",
  "github_repo": "Chrouos/RAG-base-Automatic-Peer-Review",
  "diagram_type": "block-beta",
  "code": "**Summary:**\nThe paper addresses the limitations of Neural Implicit Representation (NIR) models in handling multiple video data sets by proposing a novel method, Progressive Fourier Neural Representation (PFNR), which leverages Fourier space to enhance the model's ability to generalize and adapt to new data. This method involves transforming weights into Fourier space, allowing for a more efficient encoding of video data. The proposed method is tested on various datasets, demonstrating improvements over existing baselines in terms of PSNR and SSIM. The paper also discusses the practical implications of encoding multiple videos continually and the potential of the method in real-world applications.\n\n**Strengths:**\n- The paper benefits from generally good writing, appropriate use of mathematical language, and a highly appropriate and extensive background literature survey.\n- The proposed learning scenario is very practical in real applications, enabling the generalization ability of NIR to be evaluated.\n- The idea of combining Fourier representation with sparsification is a straightforward and novel concept, and the method provides better performance over baselines with the same capacity.\n- The experiments verify the method's ability to adapt to new training sessions and show significant improvements in performance.\n- The manuscript provides detailed metric results and abundant ablations on several hyperparameters, which are also discussed in both the main paper and the supplementary.\n- Many baselines are discussed in the related work section and compared technically in the experiments.\n\n**Weaknesses:**\n- The methodology section may be difficult for readers without a background in the domain, and the writing is not always clear.\n- The manuscript misses a comparison of the proposed method with existing baselines in terms of computational requirements, specifically whether the FSO module increases computational requirements significantly from the baseline NeRV.\n- The experiments do not verify the \"lossless decoding\" stated in the abstract, as previous videos were not evaluated.\n- The manuscript is missing comparable performance to its baselines, and the tables are hard to interpret.\n- The illustration of the proposed method is relatively limited, especially about the details in Fourier space, which might hide the novelty and complexity of the proposed method.\n- The paper is tested on only two datasets, both from the UVG series, which limits the generalizability of the results.\n- There are several minor typographical and formatting errors throughout the manuscript.\n\n**Questions:**\n- How does the proposed architecture compare with existing baselines in terms of computational requirement? Does the FSO module increase the computational requirements significantly from the baseline NeRV?\n- How many frames for each video were considered during training? Can the authors elaborate on the video frame resolution vs frame rate trade-off? What is the maximum number of frames that can be considered at a time at a certain resolution, or what is the maximum resolution that can be processed at a certain number of frames?\n- In Algorithm 1, the operation at line 7 is not differentiable. How is ∂L/∂ρ calculated?\n- Is it common to use neural implicit representation (NIR)? As I know, many works adopt the term implicit neural representation (INR) rather than NIR.\n- What is the temporal length of frames (dν in the paper)? Does dν affect the final performance?\n- What is the performance of the proposed method with Single Task Learning (STL)? Does the proposed method impact negatively due to the proposed components for continual learning?\n- How about the performance only FSO without the Conv block in the NeRV block?\n- What is the averaged PSNR and MS-SSIM performance of the proposed method and WSN on UVG8/17 with varying capacity? It is better to visualize in a plot of the performance and capacity rather than a table because the capacity of the model seems to be important for this setting.\n- The proposed method, PFNR, outperforms the upper bound, MLT. What is the reason behind this?\n- The manuscript mentions that INRs learn to memorize videos \"regardless of data relevancy or similarity.\" Shouldn't this characteristic help an INR to learn multiple unrelated videos compared to those that learn with data relevancy or similarity?\n\n**Soundness:**\n3 good\n\n**Presentation:**\n2 fair\n\n**Contribution:**\n3 good\n\n**Rating:**\n6 marginally above the acceptance threshold\n\n**Paper Decision:**\n- Decision: Accept\n- Reasons: The paper presents a novel method, PFNR, which effectively addresses the limitations of existing NIR models by leveraging Fourier space for better adaptation and generalization. The method is supported by extensive experimentation and visual results, demonstrating improvements over baselines. While there are some concerns regarding the clarity of the methodology and the need for more diverse datasets, the overall contribution and soundness of the research justify its acceptance. The decision aligns with the majority of reviewers who found the paper to be a good contribution to the field, with potential for further improvements in clarity and transparency.",
  "content_size": 5223,
  "collected_at": "2026-02-06T14:06:23.969692",
  "compilation_status": "failed",
  "compilation_error": "[WinError 2] 系统找不到指定的文件。",
  "license": "gitlab_repo",
  "license_name": "GitLab Repository",
  "license_url": "https://gitlab.com"
}